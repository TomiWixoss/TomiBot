import { ThreadType } from "../services/zalo.js";
import {
  generateWithImage,
  generateWithAudio,
  generateWithFile,
  generateWithVideo,
} from "../services/gemini.js";
import { sendResponse } from "./response.js";
import { CONFIG, PROMPTS } from "../config/index.js";
import { saveToHistory, saveResponseToHistory } from "../utils/history.js";
import { logStep, logZaloAPI, logError } from "../utils/logger.js";

export async function handleSticker(api: any, message: any, threadId: string) {
  const content = message.data?.content;
  console.log(`[Bot] üé® Nh·∫≠n sticker ID: ${content.id}`);
  logStep("handleSticker", { stickerId: content.id, threadId });

  try {
    await saveToHistory(threadId, message);

    const stickerDetails = await api.getStickersDetail(content.id);
    logZaloAPI("getStickersDetail", { stickerId: content.id }, stickerDetails);

    const stickerInfo = stickerDetails?.[0];
    const stickerUrl = stickerInfo?.stickerUrl || stickerInfo?.stickerSpriteUrl;

    await api.sendTypingEvent(threadId, ThreadType.User);
    logStep("generateWithImage", {
      prompt: "sticker",
      url: stickerUrl?.substring(0, 50),
    });

    const aiReply = await generateWithImage(PROMPTS.sticker, stickerUrl);
    logStep("aiReply", aiReply);

    await sendResponse(api, aiReply, threadId, message);

    const responseText = aiReply.messages
      .map((m) => m.text)
      .filter(Boolean)
      .join(" ");
    await saveResponseToHistory(threadId, responseText);

    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi sticker!`);
  } catch (e: any) {
    logError("handleSticker", e);
    console.error("[Bot] L·ªói x·ª≠ l√Ω sticker:", e);
  }
}

export async function handleImage(api: any, message: any, threadId: string) {
  const content = message.data?.content;
  const imageUrl = content?.href || content?.hdUrl || content?.thumbUrl;
  const caption = content?.title || content?.desc || "";

  console.log(`[Bot] üñºÔ∏è Nh·∫≠n ·∫£nh${caption ? ` + caption: "${caption}"` : ""}`);
  logStep("handleImage", {
    imageUrl: imageUrl?.substring(0, 50),
    caption,
    threadId,
  });

  try {
    await saveToHistory(threadId, message);
    await api.sendTypingEvent(threadId, ThreadType.User);

    const prompt = caption ? PROMPTS.imageWithCaption(caption) : PROMPTS.image;
    logStep("generateWithImage", { prompt: prompt.substring(0, 100) });

    const aiReply = await generateWithImage(prompt, imageUrl);
    logStep("aiReply", aiReply);

    await sendResponse(api, aiReply, threadId, message);

    const responseText = aiReply.messages
      .map((m) => m.text)
      .filter(Boolean)
      .join(" ");
    await saveResponseToHistory(threadId, responseText);

    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi ·∫£nh!`);
  } catch (e: any) {
    logError("handleImage", e);
    console.error("[Bot] L·ªói x·ª≠ l√Ω ·∫£nh:", e);
  }
}

export async function handleVideo(api: any, message: any, threadId: string) {
  const content = message.data?.content;
  const videoUrl = content?.href || content?.hdUrl;
  const thumbUrl = content?.thumb;
  const params = content?.params ? JSON.parse(content.params) : {};
  const duration = params?.duration ? Math.round(params.duration / 1000) : 0;
  const fileSize = params?.fileSize ? parseInt(params.fileSize) : 0;
  const caption = content?.title || content?.desc || ""; // Caption k√®m video

  if (caption) {
    console.log(
      `[Bot] üé¨ Nh·∫≠n video: ${duration}s, ${Math.round(
        fileSize / 1024 / 1024
      )}MB + caption: "${caption}"`
    );
  } else {
    console.log(
      `[Bot] üé¨ Nh·∫≠n video: ${duration}s, ${Math.round(
        fileSize / 1024 / 1024
      )}MB`
    );
  }

  logStep("handleVideo", {
    videoUrl: videoUrl?.substring(0, 50),
    thumbUrl: thumbUrl?.substring(0, 50),
    duration,
    fileSize,
    caption,
    threadId,
  });

  try {
    // L∆∞u video v√†o history
    await saveToHistory(threadId, message);

    await api.sendTypingEvent(threadId, ThreadType.User);

    let aiReply;
    // N·∫øu video d∆∞·ªõi 20MB th√¨ g·ª≠i video th·∫≠t, kh√¥ng th√¨ d√πng thumbnail
    if (videoUrl && fileSize > 0 && fileSize < 20 * 1024 * 1024) {
      console.log(`[Bot] üé¨ G·ª≠i video th·∫≠t cho AI xem`);
      logStep("handleVideo", "Using real video (< 20MB)");
      const prompt = caption
        ? PROMPTS.videoWithCaption(duration, caption)
        : PROMPTS.video(duration);
      aiReply = await generateWithVideo(prompt, videoUrl, "video/mp4");
    } else {
      console.log(`[Bot] üñºÔ∏è Video qu√° l·ªõn, d√πng thumbnail`);
      logStep("handleVideo", "Using thumbnail (video too large)");
      const prompt = caption
        ? PROMPTS.videoThumbWithCaption(duration, caption)
        : PROMPTS.videoThumb(duration);
      aiReply = await generateWithImage(prompt, thumbUrl);
    }

    logStep("handleVideo:aiReply", aiReply);
    await sendResponse(api, aiReply, threadId, message);

    // L∆∞u response
    const responseText = aiReply.messages
      .map((m) => m.text)
      .filter(Boolean)
      .join(" ");
    await saveResponseToHistory(threadId, responseText);

    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi video!`);
  } catch (e: any) {
    logError("handleVideo", e);
    console.error("[Bot] L·ªói x·ª≠ l√Ω video:", e);
  }
}

export async function handleVoice(api: any, message: any, threadId: string) {
  const content = message.data?.content;
  const audioUrl = content?.href;
  const params = content?.params ? JSON.parse(content.params) : {};
  const duration = params?.duration ? Math.round(params.duration / 1000) : 0;

  console.log(`[Bot] üé§ Nh·∫≠n voice: ${duration}s`);
  logStep("handleVoice", {
    audioUrl: audioUrl?.substring(0, 50),
    duration,
    threadId,
  });

  try {
    // L∆∞u voice v√†o history
    await saveToHistory(threadId, message);

    await api.sendTypingEvent(threadId, ThreadType.User);
    const aiReply = await generateWithAudio(
      PROMPTS.voice(duration),
      audioUrl,
      "audio/aac"
    );

    logStep("handleVoice:aiReply", aiReply);
    await sendResponse(api, aiReply, threadId, message);

    // L∆∞u response
    const responseText = aiReply.messages
      .map((m) => m.text)
      .filter(Boolean)
      .join(" ");
    await saveResponseToHistory(threadId, responseText);

    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi voice!`);
  } catch (e: any) {
    logError("handleVoice", e);
    console.error("[Bot] L·ªói x·ª≠ l√Ω voice:", e);
  }
}

export async function handleFile(api: any, message: any, threadId: string) {
  const content = message.data?.content;
  const fileName = content?.title || "file";
  const fileUrl = content?.href;
  const params = content?.params ? JSON.parse(content.params) : {};
  const fileExt = (params?.fileExt?.toLowerCase() || "").replace(".", "");
  const fileSize = params?.fileSize
    ? Math.round(parseInt(params.fileSize) / 1024)
    : 0;

  console.log(`[Bot] üìÑ Nh·∫≠n file: ${fileName} (.${fileExt}, ${fileSize}KB)`);
  logStep("handleFile", {
    fileName,
    fileUrl: fileUrl?.substring(0, 50),
    fileExt,
    fileSize,
    threadId,
  });

  try {
    // L∆∞u file v√†o history
    await saveToHistory(threadId, message);

    await api.sendTypingEvent(threadId, ThreadType.User);

    const {
      isGeminiSupported,
      isTextConvertible,
      fetchAndConvertToTextBase64,
    } = await import("../utils/fetch.js");
    const { generateContent, generateWithBase64 } = await import(
      "../services/gemini.js"
    );

    let aiReply;
    const mimeType = CONFIG.mimeTypes[fileExt] || "application/octet-stream";
    logStep("handleFile:mimeType", { fileExt, mimeType });

    // 1. N·∫øu Gemini h·ªó tr·ª£ native ‚Üí g·ª≠i tr·ª±c ti·∫øp
    if (isGeminiSupported(fileExt)) {
      console.log(`[Bot] ‚úÖ Gemini h·ªó tr·ª£ native: ${fileExt}`);
      logStep("handleFile", `Gemini native support: ${fileExt}`);

      // D√πng prompt ph√π h·ª£p v·ªõi lo·∫°i file
      let prompt: string;
      if (mimeType.startsWith("video/")) {
        // Video file ‚Üí d√πng prompt video
        const duration = 0; // Kh√¥ng bi·∫øt duration t·ª´ file attachment
        prompt = PROMPTS.video(duration);
        console.log(`[Bot] üé¨ X·ª≠ l√Ω nh∆∞ video`);
        logStep("handleFile", "Processing as video");
      } else if (mimeType.startsWith("audio/")) {
        // Audio file ‚Üí d√πng prompt voice
        const duration = 0;
        prompt = PROMPTS.voice(duration);
        console.log(`[Bot] üé§ X·ª≠ l√Ω nh∆∞ audio`);
        logStep("handleFile", "Processing as audio");
      } else {
        // C√°c file kh√°c (PDF, HTML, text...)
        prompt = PROMPTS.file(fileName, fileSize);
        logStep("handleFile", "Processing as document");
      }

      aiReply = await generateWithFile(prompt, fileUrl, mimeType);
    }
    // 2. N·∫øu c√≥ th·ªÉ convert sang text ‚Üí convert sang .txt v√† g·ª≠i nh∆∞ file th∆∞·ªùng
    else if (isTextConvertible(fileExt)) {
      console.log(`[Bot] üìù Convert sang .txt: ${fileExt}`);
      logStep("handleFile", `Converting to text: ${fileExt}`);
      const base64Text = await fetchAndConvertToTextBase64(fileUrl);
      if (base64Text) {
        logStep("handleFile", `Text converted: ${base64Text.length} chars`);
        aiReply = await generateWithBase64(
          PROMPTS.fileText(fileName, fileExt, fileSize),
          base64Text,
          "text/plain"
        );
      } else {
        logStep("handleFile", "Text conversion failed");
        aiReply = await generateContent(
          PROMPTS.fileUnreadable(fileName, fileExt, fileSize)
        );
      }
    }
    // 3. Kh√¥ng h·ªó tr·ª£
    else {
      console.log(`[Bot] ‚ùå Kh√¥ng h·ªó tr·ª£: ${fileExt}`);
      logStep("handleFile", `Unsupported format: ${fileExt}`);
      aiReply = await generateContent(
        PROMPTS.fileUnreadable(fileName, fileExt, fileSize)
      );
    }

    logStep("handleFile:aiReply", aiReply);
    await sendResponse(api, aiReply, threadId, message);

    // L∆∞u response
    const responseText = aiReply.messages
      .map((m) => m.text)
      .filter(Boolean)
      .join(" ");
    await saveResponseToHistory(threadId, responseText);

    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi file!`);
  } catch (e: any) {
    logError("handleFile", e);
    console.error("[Bot] L·ªói x·ª≠ l√Ω file:", e);
  }
}

/**
 * X·ª≠ l√Ω nhi·ªÅu ·∫£nh c√πng l√∫c
 */
export async function handleMultipleImages(
  api: any,
  messages: any[],
  threadId: string,
  caption?: string
) {
  const { generateWithMultipleImages } = await import("../services/gemini.js");

  console.log(
    `[Bot] üñºÔ∏è Nh·∫≠n ${messages.length} ·∫£nh${
      caption ? ` + caption: "${caption}"` : ""
    }`
  );
  logStep("handleMultipleImages", {
    imageCount: messages.length,
    caption,
    threadId,
  });

  try {
    // L∆∞u t·∫•t c·∫£ ·∫£nh v√†o history
    for (const msg of messages) {
      await saveToHistory(threadId, msg);
    }

    await api.sendTypingEvent(threadId, ThreadType.User);

    // L·∫•y URLs c·ªßa t·∫•t c·∫£ ·∫£nh
    const imageUrls = messages
      .map((msg) => {
        const content = msg.data?.content;
        return content?.href || content?.hdUrl || content?.thumbUrl;
      })
      .filter(Boolean);

    logStep("handleMultipleImages:urls", {
      urls: imageUrls.map((u: string) => u.substring(0, 50)),
    });

    // T·∫°o prompt ph√π h·ª£p
    const prompt = caption
      ? PROMPTS.multipleImagesWithCaption(imageUrls.length, caption)
      : PROMPTS.multipleImages(imageUrls.length);

    const aiReply = await generateWithMultipleImages(prompt, imageUrls);
    logStep("handleMultipleImages:aiReply", aiReply);

    await sendResponse(api, aiReply, threadId, messages[messages.length - 1]);

    // L∆∞u response
    const responseText = aiReply.messages
      .map((m) => m.text)
      .filter(Boolean)
      .join(" ");
    await saveResponseToHistory(threadId, responseText);

    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi ${messages.length} ·∫£nh!`);
  } catch (e: any) {
    logError("handleMultipleImages", e);
    console.error("[Bot] L·ªói x·ª≠ l√Ω nhi·ªÅu ·∫£nh:", e);
  }
}
